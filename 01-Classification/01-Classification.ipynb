{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8751e1fc-e839-4b29-8c1d-9aa053229f76",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "# Classification\n",
    "--- \n",
    "Classification is the process of categorizing a set of data into separate classes. Image recognition, the task of identifying the label corresponding to an image, is crucial for classification and can become difficult as number of classes increase. This tutorial will focus on using deep learning algorithms for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159b279-cac9-463f-bc2e-a192fe413330",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What is Deep Learning?\n",
    "---\n",
    "<img src=\"./Images/1.gif\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "Deep learning is a machine learning method used to train a computer to recognize patterns in data. Deep learning is useful for classification because it is customized for the training data making it more accurate than traditional classification methods. This method consists of a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain “learning” from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize and refine for accuracy. However, adding more hidden layers will reduce the training speed because the network will have more parameters (weights) to calibrate. \n",
    "\n",
    "Deep learning networks are typically trained on data for which the labels are known, then tested on data for which labels are unknown from the same dataset. \n",
    "\n",
    "In this submodule we will be experimenting with the [ResNet](https://arxiv.org/abs/1512.03385) deep learning architecture using the [1000-class Imagenet dataset](https://image-net.org/download.php) which is a large collection of images of everyday objects and [PathMNIST](https://medmnist.com/) which is a collection of pathology images. We will be using a popular technique in deep learning for classification named transfer learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00fc298-5c84-44bb-b0d0-8c40b691f864",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What is Transfer Learning?\n",
    "---\n",
    "\n",
    "Transfer learning (TL) focuses on gaining knowledge from one dataset and using it to classify data from another dataset. It leverages the already existing data so the network can quickly achieve good accuracy.\n",
    "<img src=\"./Images/2.jpg\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "### Why transfer learning?\n",
    "---\n",
    "\n",
    "Suppose you have 100 images of cats and 100 dogs and want to build a model to classify the images. This is a relatively small dataset and the network trained on this dataset would not be able to learn all the information about the data. Hence, the trained network would be less accurate on testing dataset. Enter transfer learning. There are two big reasons why you want to use transfer learning:\n",
    "\n",
    "1) Training models with high accuracy requires a lot of data. For example, the ImageNet dataset contains over 1 million images. In the real world, you are unlikely to have such a large dataset. \n",
    "\n",
    "2) Assuming that you had that kind of dataset, you might still not have the resources required to train a model on such a large dataset. \n",
    "\n",
    "Hence transfer learning makes a lot of sense if you don’t have the compute resources needed to train models on huge datasets. Even if you had the compute resources at your disposal, you still must wait for days or weeks to train such a model. Therefore, using a pre-trained model will save you precious time. \n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "To elaborate further about the effectiveness of transfer learning we will conduct 3 experiments using ResNet-18 model. This model consists of a feature extractor and a classifier. The feature extractor extracts relevant information from the images that the classifier uses for decision making (classification). \n",
    "\n",
    "The <a href=\"#A\">first experiment</a> involves training the classifier without using transfer learning. This means that all the weights are initialized randomly. All the layers of the model are trainable which means that all the parameters (weights) of the model is being optimized. \n",
    "\n",
    "In the <a href=\"#B\">second experiment</a>, we introduce transfer learning with feature extraction. We use ImageNet-1000 dataset to train the feature extractor only. We then use the trained feature extractor that leverages the information learned from ImageNet to extract the features from the new dataset (PathMNIST). The classifier is modified and trained on PathMNIST.\n",
    "\n",
    "Finally, in the <a href=\"#C\">third experiment</a>, we introduce transfer learning with feature extraction finetuning. We use ImageNet-1000 dataset to train the feature extractor. The main difference between this experiment and the previous one is the finetuning meaning that the feature extractor is not fixed and will be trained on PathMNIST. The classifier is modified and trained on PathMNIST.\n",
    "\n",
    "### Notebook workflow:\n",
    "---\n",
    "\n",
    "- <a href=\"#0\">Install and Load Dataset</a></br>\n",
    "- <a href=\"#A\">A. Training ``ResNet`` from scratch</a></br>\n",
    "    1. <a href=\"#A1\">Create ResNet-18 model with random initialization and set the weights to be learned from scratch.</a></br>\n",
    "    2. <a href=\"#A2\">Train on training dataset.</a></br>\n",
    "    3. <a href=\"#A3\">Evaluate on testing dataset.</a></br>\n",
    "- <a href=\"#B\">B. Training ``ResNet`` using Transfer Learning with Feature Extraction</a></br>\n",
    "    1. <a href=\"#B1\">Create ``ResNet-18`` Model pretrained on ``ImageNet`` and turn on learning only for final layers.</a></br>\n",
    "    2. <a href=\"#B2\">Train on training dataset.</a></br>\n",
    "    3. <a href=\"#B3\">Evaluate on testing dataset.</a></br>\n",
    "- <a href=\"#C\">C. Training ``ResNet`` using Transfer Learning without Feature Extraction</a></br>\n",
    "    1. <a href=\"#C1\">Create ``ResNet-18 Model`` pretrained on ``ImageNet`` and turn on learning on all Layers.</a></br>\n",
    "    2. <a href=\"#C2\">Train on training dataset.</a></br>\n",
    "    3. <a href=\"#C3\">Evaluate on testing dataset.</a></br>\n",
    "- <a href=\"#1\">Results</a></br>   \n",
    "- <a href=\"#2\">Conclusion</a></br>    \n",
    "### Main libraries\n",
    "---\n",
    "\n",
    "The main Python libraries that will be used in this tutorial are:\n",
    "\n",
    "* ``pytorch`` and ``torchvision``: these libraries focus on designing machine learning models.\n",
    "* ``medmnist``: this library is specifically designed for reading and processing the MedMNIST dataset. It includes functions for data preperation and formating.\n",
    "* ``tqdm``: a library used to display the progress of code loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc753c-bb7b-430e-8cbe-c587b8affa23",
   "metadata": {},
   "source": [
    "## <a name=\"0\">Install and Load Dataset</a> \n",
    "---\n",
    "``PathMNIST`` is mainly used to predict survival in cancer histological sections. They are Images of size 3 × 28 × 28 pixels. The PathMNIST dataset consists of 9 classes and the number of images are 107,180 split into (training / validation / testing) as (89,996 / 10,004 / 7,180) respectivly.\n",
    "\n",
    "In the following steps we demonstrate how download the PathMNIST dataset and install the library used to manipulate it.\n",
    "\n",
    "We start by running pip installer to install necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd6aff-6edf-4393-92d8-66bfcc303a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install medmnist torchshow torchvision torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863588e-1c1d-4c61-ae4f-466caed0b060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PrepareDataset import Prepare_Data, Get_DataSet_Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbc7bc-e58c-46a4-b899-96f6f48ee359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Loops import train_loop,test_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8179025-ee38-46ed-8474-d3ddeba28eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import Create_Model_Optimizer_Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82943a70-9b02-45f8-97e1-f0e61e0bd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Train_Loader,Val_Loader,Test_Loader,Train_Evaluator,Test_Evaluator) = Prepare_Data(data_flag = 'pathmnist', download = True, batch_size = 128)\n",
    "(Task, Num_Classes) = Get_DataSet_Information(data_flag = 'pathmnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aecbde-edb1-4ed0-91c1-15e3a526d441",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Knowledge Check</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb528c-6b1e-43ec-9aa2-3d1302a35fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyterquiz==2.0.7 --quiet\n",
    "from jupyterquiz import display_quiz\n",
    "display_quiz('../quiz_files/submodule_01/kc1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27581088-a0ee-4452-a7de-7a468dee3c86",
   "metadata": {},
   "source": [
    "## <a name=\"A\">A. Training ``ResNet`` from scratch</a> \n",
    "---\n",
    "In the following steps we demonstrate how to train a ResNet Model from scratch. The weights for all the layers are initialized randomly and learned throughout the training process only on PathMNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f98059-e395-400f-a2e8-4c1153422f66",
   "metadata": {},
   "source": [
    "####    1. <a name=\"A1\">Create ``ResNet-18`` model with random initialization and set the weights to be learned from scratch.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60176bea-d8e0-46fe-9eeb-01082c75bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Model, Optimizer, Criterion) = Create_Model_Optimizer_Criterion(n_classes = Num_Classes, feature_extract = False, use_pretrained = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2580c20-2989-4fe8-91cf-626a6f5e2449",
   "metadata": {},
   "source": [
    "####    2. <a name=\"A2\">Train on training dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe8967-8638-46d6-9c4f-5f400d3102a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scratch = train_loop(Model, Train_Loader, Val_Loader, Criterion, Optimizer, Train_Evaluator, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90d7aa-7dca-429c-9388-c13f22913a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "####    3. <a name=\"A3\">Evaluate on testing dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f925d42-a3c2-419e-9021-20ea369e046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ScratchMetric = test_loop(Model,Test_Loader,Test_Evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02319e-cc69-4650-ad3d-5e6f6ec58249",
   "metadata": {},
   "source": [
    "## <a name=\"B\">B. Training ``ResNet`` using Transfer Learning with Feature Extraction</a> \n",
    "---\n",
    "In the following steps we demonstrate how to use a ResNet Model pretrained on ImageNet and retrain the last layer on the PathMNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83dd09-61f4-455c-bc72-fc2f997f8ba2",
   "metadata": {},
   "source": [
    "\n",
    "####    1. <a name=\"B1\">Create ``ResNet-18`` Model pretrained on ``ImageNet`` and turn on learning only for final layers.</a> \n",
    "\n",
    "Note that we set feature_extract = True and use_pretrained=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05294b5d-321c-4c9e-8d6a-94305d30fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Model, Optimizer, Criterion) = Create_Model_Optimizer_Criterion(n_classes = Num_Classes, feature_extract = True, use_pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5df01-9d22-4fbd-9fb1-84b961e41860",
   "metadata": {},
   "source": [
    "####    2. <a name=\"B2\">Train on training dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b90e4-26bb-4242-8c8c-a52018cfe84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalLayers = train_loop(Model, Train_Loader, Val_Loader, Criterion, Optimizer, Train_Evaluator, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c468f8c0-67c3-4852-b0d8-db8c0aa011bb",
   "metadata": {},
   "source": [
    "####    3. <a name=\"B3\">Evaluate on testing dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578159f-0a44-456d-a604-bdb936e59c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalLayerMetric = test_loop(Model,Test_Loader,Test_Evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7befb58c-2539-40de-9f89-8377795eee83",
   "metadata": {},
   "source": [
    "## <a name=\"C\">C. Training ``ResNet`` using Transfer Learning without Feature Extraction</a> \n",
    "---\n",
    "In the following steps we demonstrate how to use a pretrained ResNet Model on ImageNet and train the all layers on PathMNIST. In this case the weights of ResNet model are transfered from ImageNet dataset and used as a starting weights for learning on PathMNIST. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed9a49-7f35-4e5f-a04c-f79d1f5b75e7",
   "metadata": {},
   "source": [
    "####    1. <a name=\"C1\">Create ``ResNet-18`` Model pretrained on ImageNet and turn on learning on all Layers</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c000ce6-c09f-4e00-9fe4-51c4692e6441",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Model, Optimizer, Criterion) = Create_Model_Optimizer_Criterion(n_classes = Num_Classes, feature_extract = False, use_pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595de81-0dd6-41d5-8ee0-585f4bfef949",
   "metadata": {},
   "source": [
    "####    2. <a name=\"C2\">Train on training dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856930f5-65cb-4516-bac7-e1d60713f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FineTuned = train_loop(Model, Train_Loader, Val_Loader, Criterion, Optimizer, Train_Evaluator, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9213a5a-4b78-419d-8ba1-b07d9d40cb2d",
   "metadata": {},
   "source": [
    "####    3. <a name=\"C3\">Evaluate on testing dataset.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247c3b7-3957-4b96-951d-267eaa95542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FineTunedMetric = test_loop(Model,Test_Loader,Test_Evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b0c5c-2f1b-40d3-826b-7fa738218cea",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Knowledge Check</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396bec7-9af8-4d03-a1b0-8a853ab5fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_quiz('../quiz_files/submodule_01/kc2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be2144-6892-43ba-ac09-ec95c66a4be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"1\">Results</a> \n",
    "---\n",
    "We start by comparing the accuracies during training of the three experiments. We compare the testing accuracies on PathMNIST. Accuracy is a widely used metric that measures how well the predicted labels match the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b577585-b8b4-41bb-947a-9608dd18ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning methods and\n",
    "#  the model trained from scratch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "SHlist = [float(h) for h in Scratch]\n",
    "FLlist = [float(h) for h in FinalLayers]\n",
    "FTlist = [float(h) for h in FineTuned]\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,6),SHlist,label=\"Random Initilization\")\n",
    "plt.plot(range(1,6),FLlist,label=\"Transfter Learning Feature Extraction\")\n",
    "plt.plot(range(1,6),FTlist,label=\"Transfter Learning Fine Tuning All Layers\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, 6, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f1d56-6f26-45e5-b60a-824cbca49c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test comparison\n",
    "data = {}\n",
    "data['Random Initilization']=ScratchMetric[1]\n",
    "data['Transfer Learning Feature Extraction']=FinalLayerMetric[1]\n",
    "data['Transfer Learning Fine Tuning']=FineTunedMetric[1]\n",
    "networks = list(data.keys())\n",
    "accuracies = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(networks[0], accuracies[0], color ='blue',\n",
    "        width = 0.3)\n",
    "plt.bar(networks[1], accuracies[1], color ='red',\n",
    "        width = 0.3)\n",
    "plt.bar(networks[2], accuracies[2], color ='green',\n",
    "        width = 0.3)\n",
    "plt.ylim((0.6,1.))\n",
    "\n",
    "plt.xlabel(\"ResNet-18 Networks\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Test Set Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67535d-4b89-493a-850e-d49ce7e7d6d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Knowledge Check</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e777d9-760d-4e1c-b693-5873fe92cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_quiz('../quiz_files/submodule_01/kc3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359d078-8e57-4607-907e-0616c07b2e74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"2\">Conclusion</a> \n",
    "---\n",
    "The results show that using transfer learning and learning all the weights of the network (fine-tuning) achieves the highest accuracy. It shows that we can leverage a pre-trained model to learn features of a new dataset quickly and accurately. \n",
    "Using transfer learning with feature extraction and only learning the last layers is the fastest to train but with less parameters to learn the accuracy of the model on the testing is lower than learning all the weights either from scratch or using pre-trained ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d54d1-b2b8-406d-bae2-463f8c60c925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
